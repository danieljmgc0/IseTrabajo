\documentclass[a4paper,12pt]{report}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage[spanish,es-tabla]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{hyperref}

\geometry{margin=3cm}



% Formato de Bibliografia
\usepackage[backend=biber, sorting=none]{biblatex}
\addbibresource{biblio.bib}
\usepackage{csquotes}



\begin{document}

\begin{titlepage}
    \centering
    \vspace*{3cm}
    {\Huge\bfseries Trabajo 1: Diseño de un experimento controlado \par}
    \vspace{2cm}
    {\Large\itshape Daniel Jiménez García \par}
    {\Large\itshape Sergio Muñoz Gómez \par}
    {\Large\itshape Ángela Caiqing Pousada Morán \par}
    \vspace{1cm}
    {\Large\itshape Fecha: \today \par}
    \vfill
    {\large Master MITSS. ISE \par}
    {\large Universidad Politécnica de Valencia\par}
\end{titlepage}


% -------------------------------------------------------------------
\chapter*{Resumen}
\addcontentsline{toc}{chapter}{Resumen}

Añadir resumen después de terminar el trabajo


% -------------------------------------------------------------------
\chapter{Motivación}

\section{Problema a investigar}
Actualmente existen diversos métodos a la hora de evaluar la experiencia de usuario cuando estos utilizan sistemas interactivos. El problema que se aborda en este trabajo es la falta de evidencia empírica que permita comparar la \textbf{efectividad} cuando aplican un método empírico (\textit{A/B Testing}) frente a un método de inspección grupal (\textit{Recorrido Pluralista}).

\section{Definición del experimento}
Analizar los métodos de evaluación de usabilidad \textbf{A/B Testing} y \textbf{Recorrido Pluralista} con el propósito de comparar la capacidad para detectar problemas de usabilidad y medir su impacto en la satisfacción y eficiencia de los evaluadores.


\section{Contexto}
Para este experimento se parte de una actividad previa que se supone realizada. Esta actividad previa consiste en la evaluacón de una interfaz gráfica por parte de un equipo desarrollador sobre unos usuarios usando los dos métodos de evaluación \textbf{A/B Testing} y \textbf{Recorrido Pluralista}. Así pues, nuestro estudio se centra en recopilar información de cómo ha sido la experiencia de estos desarrolladores usando las dos técnicas de evaluación

% -------------------------------------------------------------------
\chapter{Trabajos relacionados}

Diversos estudios previos han comparado métodos de evaluación de usabilidad. Nielsen \cite{nielsen1994usability} definió la \textit{Evaluación Heurística} como técnica de inspección informal realizada por expertos, mientras que Rubin \cite{rubin2011handbook} destacaron la importancia de los métodos empíricos como el \textit{User Testing} para observar comportamientos reales.  

El \textbf{A/B Testing} se utiliza ampliamente en el ámbito web para medir diferencias en satisfacción y eficiencia entre dos versiones de una interfaz \cite{kohavi2009controlled}. Por su parte, el \textbf{Recorrido Pluralista} \cite{biasPluralistic} combina la revisión de expertos, diseñadores y usuarios, permitiendo identificar problemas desde perspectivas diversas.

%A pesar de su uso extendido, no existen suficientes estudios comparativos entre ambos métodos bajo condiciones controladas, especialmente considerando variables subjetivas como satisfacción o percepción de facilidad de uso.

% -------------------------------------------------------------------
\chapter{Descripción del diseño}

\section{Hipótesis y variables}

Nuestro experimento está enfocado en comprobar qué método ofrece mejores resultados a la hora de encontrar fallos en el diseño de la interfaz y cuál prefieren los desarrollodores. \\
\vspace{0.1cm}
\textbf{Hipótesis:}
\begin{itemize}
    \item $H_{01}$: No existen diferencias significativas en los \textbf{errores percibidos} entre A/B Testing y Recorrido Pluralista.  
    \item $H_{11}$: Existen diferencias significativas en los \textbf{errores percibidos} entre A/B Testing y Recorrido Pluralista.
        \item $H_{02}$: No existen diferencias significativas en la \textbf{preferencia de uso de una metodogía frente a la otra} por parte de los desarrolladores.  
    \item $H_{12}$: Existen diferencias significativas en la \textbf{preferencia de uso de una metodogía frente a la otra} por parte de los desarrolladores.
\end{itemize}

\textbf{Variables:}
\begin{itemize}
    \item \textbf{Variable independiente:} Método de evaluación (A/B Testing, Recorrido Pluralista).
    \item \textbf{Variables dependientes:}
    \begin{itemize}
        \item \textbf{Errores:} cometidos en el uso de la interfaz
        \item \textbf{Preferencia:} por parte de los desarroladores
    \end{itemize}
    \item \textbf{Variables de control:} tipo de tarea, complejidad del prototipo, experiencia previa de los participantes.
\end{itemize}

Los errores producidos por los usuarios podemos definirlos como una variable objetiva que mide el número de tareas realizadas de manera incorrecta sobre el total de las planteadas por el equipo tal y como se muestra en la ecuación \ref{ecuacion:errores}

\begin{equation}
Errores = \frac{Tareas\ realizadas\ mal}{Total\ tareas\ realizadas}
\label{ecuacion:errores}
\end{equation}

Por otra parte, la satisfacción de los dessarrolladores es una variable subjetiva que se medirá aplicando el uso de el cuestionario mostrado en el Anexo \ref{anexo:encuesta}. 

\section{Diseño del experimento}
Como se ha comentado, este experimento se desarrollaría después realizar la evaluación de la interfaz con las dos metodoglías por parte de los desarrolladores. Estas pruebas deben haber sido llevadas a cabo por dos grupos independites de desarrolladores aplicando cada uno los dos métodos de evaluación. Como se muestra en la tabla \ref{tab:diseño_experimento} cada equipo desarrollador evalua a otro dos grupos de usuarios (A. B, C y D) también independientes para que no producir sesgos en el experimento fruto del aprendizaje durante el experimento. Este enfoque del experimento es por un lado \textit{between-subjects} en la parte de los usuarios y por otra parte \textit{within-subjects} en el estudio de la satisfacción de los desarrolladores. Esto es debido a que se aleatoriza la selección de usuarios para cada método, y los desarrolladores aplican ambos para su estudio. 

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Grupo} & \textbf{A/B Testing} & \textbf{Recorrido Pluralista} \\ \hline
\textbf{Desarrolladores 1} & A & B \\ \hline
\textbf{Desarrolladores 2} & C & D \\ \hline
\end{tabular}
\caption{Diseño del experimento entre grupos (between-subjects)}
\label{tab:diseño_experimento}
\end{table}

Las tareas que deberán haber hecho los usuarios incluiyen actividades representativas de un uso real de la aplicación. El grupo de desarrolladores asignado al método de A/B Testing centrará su evaluación en la comparación de dos versiones de la interfaz, registrando métricas cuantitativas como el tiempo medio de ejecución, la tasa de éxito de las tareas y la frecuencia de errores entre otros. Por su parte, el grupo que emplee el Recorrido Pluralista llevará a cabo una revisión colaborativa, analizando las mismas tareas y discutiendo colectivamente los problemas de usabilidad identificados.


Una vez finalizada esa evaluación, se dará paso a nuestro estudio comparativo de ambos métodos. Nuesto estudio involucrará los errores encontrados en el estudio anterior reportado por los desarrolladores y el análisis de una encuesta realizada a los desarrolladores para medir su grado de satisfacción con los métodos empleados.

El proceso de evaluación más concretamente queda descrito como sigue. Primero dos equipos desarrolladores aplican las dos técnicas de evaluación sobre grupos de usuarios independientes. Con esta evaluación recuperan datos de los errores caputarados por estos. 


\section{Selección de sujetos}

La selección de los participantes se realizará de manera intencionada, buscando garantizar la representatividad del perfil de usuario objetivo del estudio: desarrolladores de software con conocimientos básicos en usabilidad o experiencia de usuario (UX). Dado que el propósito del experimento es comparar la aplicación de los métodos A/B Testing y Recorrido Pluralista desde la perspectiva de evaluadores técnicos, resulta fundamental que los sujetos cuenten con una comprensión general de los principios de diseño de interfaces y evaluación de sistemas interactivos.

El estudio se dirigirá a un grupo de entre 16 y 20 participantes, un tamaño muestral adecuado para un diseño intra-sujetos contrabalanceado, donde cada participante aplica ambos métodos. Este rango permite obtener una potencia estadística suficiente para detectar diferencias de tamaño medio (Cohen's $d \approx 0.5$) con un nivel de significación de 0.05, reduciendo a la vez la variabilidad interindividual.

\subsection*{Criterios de inclusión}
\begin{itemize}
    \item Ser desarrollador o estudiante avanzado de ingeniería de software, diseño de interacción o disciplinas afines.
    \item Poseer conocimientos básicos sobre usabilidad o experiencia de usuario, acreditados mediante formación previa o experiencia práctica.
    \item Tener familiaridad con interfaces web interactivas.
    \item Contar con disponibilidad para asistir a dos sesiones experimentales, separadas por al menos 24 horas.
    \item Aceptar voluntariamente participar en el estudio, firmando el consentimiento informado.
\end{itemize}

\subsection*{Criterios de exclusión}
\begin{itemize}
    \item Haber participado previamente en el piloto del experimento o en estudios similares que involucren los mismos métodos.
    \item Poseer un conocimiento profundo o especializado sobre los prototipos empleados, lo que podría sesgar la evaluación.
    \item Presentar dificultades técnicas o de comunicación que impidan el correcto desarrollo de las tareas experimentales.
\end{itemize}

\subsection*{Procedimiento de reclutamiento}
Los participantes serán reclutados a través de convocatorias internas en facultades de ingeniería y diseño, y mediante invitaciones personales a profesionales en activo del ámbito del desarrollo web. Se ofrecerá información detallada sobre los objetivos del estudio, la naturaleza de las tareas a realizar y la duración estimada de cada sesión (aproximadamente 60 minutos). La participación será voluntaria y no remunerada, aunque se podrá ofrecer una constancia de participación académica.

Antes de iniciar el experimento, cada participante completará un cuestionario demográfico donde se recogerán datos como edad, nivel educativo, años de experiencia en desarrollo, conocimiento previo de técnicas de evaluación de usabilidad y frecuencia de participación en proyectos web. Esta información servirá para describir la muestra y analizar posibles correlaciones entre la experiencia previa y las percepciones de los métodos evaluados.

\subsection*{Consideraciones éticas}
El estudio cumplirá con los principios éticos establecidos por la Declaración de Helsinki y las normas institucionales sobre investigación con participantes humanos. Todos los sujetos firmarán un consentimiento informado en el que se garantice:
\begin{itemize}
    \item La confidencialidad de los datos recogidos.
    \item El uso exclusivo de la información con fines académicos y de investigación.
    \item La posibilidad de abandonar el estudio en cualquier momento, sin consecuencias.
\end{itemize}
Asimismo, los datos personales serán anonimizados y almacenados de forma segura, cumpliendo con la normativa de protección de datos vigente.

\section{Objetos e instrumentación}

Los objetos experimentales estarán constituidos por una aplicación web interactiva desarrollada en dos versiones diferenciadas, 
denominadas versión A y versión B, que presentan las mismas funcionalidades y flujo de tareas, pero difieren en determinados elementos visuales o de disposición. 
Estas variaciones se introducen con el fin de posibilitar la aplicación del método A/B Testing, que requiere comparar la interacción de los usuarios con dos variantes del mismo sistema.
En cambio, para la aplicación del Recorrido Pluralista se empleará una única versión de la aplicación (la versión B), 
sobre la que se realizará un análisis colaborativo de la interacción.

El objeto principal del experimento es evaluar la percepción de los desarrolladores 
tras aplicar ambos métodos de evaluación de usabilidad. 
Los desarrolladores no son los sujetos que ejecutan las tareas, 
sino los evaluadores que orquestan y supervisan las pruebas con grupos de usuarios reales, 
aplicando cada metodología y observando los resultados obtenidos.

De esta forma, el estudio busca analizar cómo valoran los desarrolladores la utilidad, 
facilidad de aplicación, carga de trabajo y eficacia percibida de cada método una vez que han tenido la oportunidad de ponerlos en práctica.

Cada desarrollador aplicará ambos métodos de manera secuencial y contrabalanceada de modo que algunos comiencen con A/B Testing y otros con Recorrido Pluralista con el objetivo de evitar sesgos derivados del orden o de la experiencia acumulada.
Después de la aplicación de ambos métodos, los desarrolladores completarán un cuestionario de valoración comparativa, expresando su opinión y grado de satisfacción con cada técnica.

Durante la aplicación del método A/B Testing, cada desarrollador coordinará sesiones individuales en las que los usuarios interactuarán con las versiones A y B del prototipo. 
Se registrarán métricas como tiempo de ejecución, tasa de éxito y errores cometidos por los usuarios, además de observaciones sobre los problemas detectados.

En el caso del Recorrido Pluralista, el desarrollador dirigirá sesiones grupales en las que los usuarios trabajarán junto 
con un diseñador gráfico y un experto en usabilidad. 
Durante estas sesiones se recorrerán de forma colaborativa las tareas de la aplicación, discutiendo los pasos de interacción, 
los problemas encontrados y las posibles mejoras de diseño.

Una vez completadas ambas fases, los desarrolladores valorarán su experiencia como evaluadores, indicando qué método consideran más eficaz, intuitivo y práctico para la identificación de problemas de usabilidad y 
para su aplicación en contextos reales de desarrollo.

Para la obtención de información se emplearán instrumentos orientados a recoger datos cuantitativos y cualitativos, tanto de los usuarios como de los desarrolladores:


\begin{itemize}
    \item Registro del tiempo empleado por los usuarios en la ejecución de las tareas, medido mediante software o cronómetro digital, con el fin de evaluar la eficiencia del método.
    \item Documentación de problemas de usabilidad, recogida por los desarrolladores en una plantilla estructurada con la descripción, severidad y frecuencia de cada incidencia.
    \item Cuestionario SUS, administrado a los usuarios tras la interacción con la aplicación, para evaluar la percepción de usabilidad de las versiones A y B.
    \item Cuestionario de valoración del método, cumplimentado por los desarrolladores al finalizar la aplicación de ambas metodologías, diseñado específicamente para medir su satisfacción, facilidad de aplicación y preferencia entre los métodos.
    \item Escala de satisfacción general tipo Likert (1–7), para cuantificar la valoración global de los desarrolladores sobre la experiencia de uso de cada técnica.
    \item Preguntas abiertas, destinadas a recoger percepciones cualitativas sobre las ventajas, limitaciones y dificultades encontradas durante la aplicación de los métodos.

\end{itemize}



Antes del inicio del experimento, los desarrolladores y usuarios completarán un cuestionario demográfico donde se recogerán datos relativos a edad, formación, experiencia en desarrollo de software y familiaridad con técnicas de evaluación de usabilidad. Durante las sesiones del Recorrido Pluralista, se realizarán observaciones directas y registro de comentarios verbales por parte de los desarrolladores, con el fin de complementar los datos cuantitativos con información cualitativa sobre las percepciones y dinámicas de grupo.
Todos los datos recopilados serán tratados de forma confidencial y anonimizados, garantizando la protección de la información personal y el cumplimiento de los principios éticos establecidos para investigaciones con participantes humanos.

\section{Evaluación de la validez}
En este apartado se evalúa la validez del diseño experimental propuesto, identificando posibles amenazas y las 
medidas adoptadas para solucionarlas, con el fin de garantizar la robustez y fiabilidad de los resultados.



\textbf{Validez interna:} Se han identificado varias amenazas que podrían afectar a la relación causal entre el método 
de evaluación y los resultados: 
\begin{itemize}
    \item \textbf{Efecto del orden:} Dado que los desarrolladores aplican ambos métodos, se empleará un diseño contrabalanceado para controlar el efecto del orden de aplicación.
    \item \textbf{Efecto aprendizaje:} La exposición previa a un método podría influir en el desempeño. Para minimizarlo, se utilizarán prototipos y tareas equivalentes pero distintas en cada método, y se garantizará que los grupos de usuarios sean independientes.
    \item \textbf{Fatiga:} La sesiones de evaluación estarán separadas por al menos 24 horas para reducir el cansancio de los participantes. 
    \item \textbf{Experiencia previa:} Se recogerán datos demográficos y de experiencia mediante un cuestionario inicial.
\end{itemize}

\textbf{Validez de conclusión estadística:} Para asegurar que las diferencias observadas en los errores detectados y la 
satisfacción de los desarrolladores se deben a los métodos de evaluación comparados y no a factores aleatorios, 
se utilizarán pruebas estadísticas adecuadas. En concreto, se aplicarán pruebas t pareadas para comparar los resultados intra-sujetos (satisfacción de 
desarrolladores) y pruebas t independientes para los datos entre grupos (errores de usuarios). En caso de que no se cumpla el 
supuesto de normalidad, se recurrirá a pruebas no paramétricas equivalentes (Wilcoxon y Mann-Whitney respectivamente).
Se adoptarán un nivel de significación de $\alpha=0.05$ y se calcularán tamaños del efecto (Cohen’s d) para cuantificar la magnitud de las diferencias encontradas.

\textbf{Validez externa:} El contexto de experimento permite generalizar los resultados a entornos similares de evaluación de usabilidad en en ámbito wev con evaluadores semi-expertos. Sin embargo, la selección 
intencionada de participantes y el uso de un único tipo de interfaz pueden limitar la generalización a otros dominios o perfiles de usuario. Para futuras réplicas, se recomienda ampliar la variedad de prototipos y perfiles de evaluadores.

\textbf{Validez de constructo:} Se han seleccionado instrumentos de medición para operacionalizar las variables de estudio: 
\begin{itemize}
    \item \textbf{Errores detectados:} La variable errores se medirá de forma objetiva mediante la fórmula definida en la ecuación \ref{ecuacion:errores}, asegurando una evaluación cuantitativa y comparable entre métodos.
    \item \textbf{Satisfacción y percepción de usabilidad:} La satisfacción y percepción de usabilidad se medirán con el cuestionario SUS y una escala Likert de 7 puntos, ambos con alta fiabilidad y validez contrastada en estudios de usabilidad.
    \item \textbf{Preguntas abiertas:} Permitirán capturar aspectos cualitativos que enriquezcan la interpretación de los resultados.
\end{itemize}

% BIBLIOGRAFIA %
\cleardoublepage

\printbibliography[heading=bibintoc,title={Bibliografía}]
% -------------------------------------------------------------------
\appendix
\chapter{Anexo I: Cuestionario para usuarios}
\label{anexo:usuarios}

Instrucciones: Rellene el cuestionario tras completar las tareas con la aplicación.

\begin{itemize}
    \item Escala SUS (System Usability Scale) — 10 ítems, respuestas 1 (totalmente en desacuerdo) a 5 (totalmente de acuerdo).
    \item Preguntas de rendimiento percibido:
    \begin{itemize}
        \item ¿Pudo completar las tareas propuestas? (Sí/No)
        \item Tiempo estimado para completar cada tarea (segundos/minutos).
        \item Observaciones sobre dificultades encontradas (respuesta abierta).
    \end{itemize}
    \item Comentarios abiertos sobre la experiencia de uso: ¿qué aspectos le resultaron más confusos o útiles?
\end{itemize}

\chapter{Anexo II: Cuestionario para desarrolladores}
\label{anexo:desarrolladores}

El cuestionario se realizó en el siguiente \href{https://docs.google.com/forms/d/1ct0bRRyEHIIYPp2TrhZ53o755vneEbUIfic6f0XR7HM}{enlace}.


Instrucciones: Complete este cuestionario después de haber aplicado ambos métodos de evaluación de usabilidad (\textit{A/B Testing} y \textit{Recorrido Pluralista}) con los grupos de usuarios asignados. Las respuestas deben reflejar su experiencia como desarrollador al coordinar y aplicar cada metodología.

\begin{itemize}
    \item \textbf{Sección 1 — Facilidad de aplicación (escala Likert 1 = totalmente en desacuerdo, 5 = totalmente de acuerdo):}
    \begin{itemize}
        \item Entendí rápidamente cómo aplicar el método A/B Testing.
        \item Entendí rápidamente cómo aplicar el método de Recorrido Pluralista.
        \item La documentación o guía del método A/B Testing fue clara y suficiente.
        \item La dinámica del Recorrido Pluralista fue fácil de seguir.
        \item Me resultó sencillo identificar pasos concretos al aplicar A/B Testing.
        \item Me resultó sencillo coordinar y ejecutar las sesiones del Recorrido Pluralista.
        \item En general, considero que el método [A/B Testing / Recorrido Pluralista] es fácil de aplicar.
    \end{itemize}

    \item \textbf{Sección 2 — Eficiencia percibida (escala Likert 1 = totalmente en desacuerdo, 5 = totalmente de acuerdo):}
    \begin{itemize}
        \item El tiempo necesario para preparar un A/B Testing es razonable.
        \item El tiempo necesario para preparar un Recorrido Pluralista es razonable.
        \item Aplicar A/B Testing requiere menos esfuerzo que otros métodos de evaluación.
        \item El Recorrido Pluralista requiere demasiado esfuerzo de coordinación.
        \item El análisis de resultados en A/B Testing me resultó rápido y claro.
        \item El análisis de resultados del Recorrido Pluralista fue sencillo de interpretar.
    \end{itemize}

    \item \textbf{Sección 3 — Utilidad y efectividad del método (escala Likert 1 = totalmente en desacuerdo, 5 = totalmente de acuerdo):}
    \begin{itemize}
        \item A/B Testing permite detectar problemas de usabilidad relevantes.
        \item El Recorrido Pluralista permite identificar problemas de usabilidad relevantes.
        \item A/B Testing ofrece evidencia objetiva sobre la experiencia del usuario.
        \item El Recorrido Pluralista permite comprender mejor el razonamiento del usuario.
        \item Los resultados obtenidos con A/B Testing son fácilmente comunicables al equipo de desarrollo.
        \item Los resultados del Recorrido Pluralista son útiles para mejorar el diseño del sistema.
        \item En mi experiencia, ambos métodos complementan bien el proceso de evaluación de usabilidad.
    \end{itemize}

    \item \textbf{Sección 4 — Satisfacción general y preferencia (escala Likert 1 = totalmente en desacuerdo, 5 = totalmente de acuerdo):}
    \begin{itemize}
        \item Me sentí cómodo utilizando el método A/B Testing.
        \item Me sentí cómodo utilizando el método Recorrido Pluralista.
        \item Me resultó más interesante aplicar A/B Testing que el Recorrido Pluralista.
        \item Considero que el Recorrido Pluralista fomenta mejor la colaboración entre los evaluadores.
        \item Preferiría usar A/B Testing en futuros proyectos de evaluación.
        \item Preferiría usar Recorrido Pluralista en futuros proyectos de evaluación.
        \item En general, estoy satisfecho con la calidad de los resultados obtenidos con ambos métodos.
    \end{itemize}

    \item \textbf{Sección 5 — Preguntas abiertas (análisis cualitativo):}
    \begin{itemize}
        \item ¿Qué ventajas destacarías del método A/B Testing en comparación con el Recorrido Pluralista?
        \item ¿Qué limitaciones o dificultades encontraste al aplicar cada método?
    \end{itemize}
\end{itemize}


\end{document}