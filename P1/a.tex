\documentclass[a4paper,12pt]{report}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage[spanish,es-tabla]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\geometry{margin=3cm}



% Formato de Bibliografia
\usepackage[backend=biber, sorting=none]{biblatex}
\usepackage{csquotes}



\begin{document}

\begin{titlepage}
    \centering
    \vspace*{3cm}
    {\Huge\bfseries Trabajo 1: Diseño de un experimento controlado \par}
    \vspace{2cm}
    {\Large\itshape Daniel Jiménez García \par}
    {\Large\itshape Sergio Muñoz Gómez \par}
    {\Large\itshape Ángela Caiqing Pousada Morán \par}
    {\Large\itshape Felipe Garín Bello \par}
    \vspace{1cm}
    {\Large\itshape Fecha: \today \par}
    \vfill
    {\large Master MITSS. ISE \par}
    {\large Universidad Politécnica de Valencia\par}
\end{titlepage}


% -------------------------------------------------------------------
\chapter*{Resumen}
\addcontentsline{toc}{chapter}{Resumen}

Añadir resumen después de terminar el trabajo


% -------------------------------------------------------------------
\chapter{Motivación}

\section{Problema a investigar}
En la actualidad existen numerosos métodos para evaluar la usabilidad y experiencia de usuario (UX) a la hora de utilziar sistemas interactivos. Sin embargo, no existe un consenso claro sobre cuál de ellos resulta más adecuado para cada sistema.  
El problema que se aborda en este trabajo es la falta de evidencia empírica que permita comparar la \textbf{efectividad, eficiencia y satisfacción de los evaluadores} cuando aplican un método empírico (\textit{A/B Testing}) frente a un método de inspección grupal (\textit{Recorrido Pluralista}).

\section{Definición del experimento}
Analizar los métodos de evaluación de usabilidad \textbf{A/B Testing} y \textbf{Recorrido Pluralista} con el propósito de comparar su capacidad para detectar problemas de usabilidad y medir su impacto en la satisfacción y eficiencia de los evaluadores.


\section{Contexto}
El experimento se llevará a cabo en un entorno controlado de laboratorio, sobre un prototipo web de complejidad media. Se contará con estudiantes de ingeniería de software y diseño UX como participantes. Cada sesión incluirá la realización de tareas específicas dentro del sistema y la evaluación mediante uno de los dos métodos propuestos.

% -------------------------------------------------------------------
\chapter{Trabajos relacionados}

Diversos estudios previos han comparado métodos de evaluación de usabilidad. Nielsen (1994) definió la \textit{Evaluación Heurística} como técnica de inspección rápida, mientras que Rubin y Chisnell (2008) destacaron la importancia de los métodos empíricos como el \textit{User Testing} para observar comportamientos reales.  

El \textbf{A/B Testing} se utiliza ampliamente en el ámbito web para medir diferencias en satisfacción y eficiencia entre dos versiones de una interfaz (Kohavi et al., 2009). Por su parte, el \textbf{Recorrido Pluralista} (Bias, 1994) combina la revisión de expertos, diseñadores y usuarios, permitiendo identificar problemas desde perspectivas diversas.

A pesar de su uso extendido, no existen suficientes estudios comparativos entre ambos métodos bajo condiciones controladas, especialmente considerando variables subjetivas como satisfacción o percepción de facilidad de uso.

% -------------------------------------------------------------------
\chapter{Descripción del diseño}

\section{Hipótesis y variables}

\textbf{Hipótesis:}
\begin{itemize}
    \item $H_{01}$: No existen diferencias significativas en la \textbf{satisfacción} entre A/B Testing y Recorrido Pluralista.  
    \item $H_{11}$: A/B Testing genera mayor satisfacción percibida que el Recorrido Pluralista.
    \item $H_{02}$: No existen diferencias significativas en la \textbf{usabilidad percibida} entre los métodos.  
    \item $H_{12}$: El Recorrido Pluralista detecta más problemas de usabilidad que A/B Testing.
    \item $H_{03}$: No existen diferencias significativas en la \textbf{eficiencia} (tiempo medio de tareas).  
    \item $H_{13}$: Los evaluadores son más eficientes (menor tiempo) usando A/B Testing.
\end{itemize}

\textbf{Variables:}
\begin{itemize}
    \item \textbf{Variable independiente:} Método de evaluación (A/B Testing, Recorrido Pluralista).
    \item \textbf{Variables dependientes:}
    \begin{itemize}
        \item \textbf{Satisfacción:} medida mediante cuestionario Likert (1--7).
        \item \textbf{Usabilidad:} puntuación SUS (\textit{System Usability Scale}).
        \item \textbf{Eficiencia:} tiempo promedio (en segundos) para completar tareas.
    \end{itemize}
    \item \textbf{Variables de control:} tipo de tarea, complejidad del prototipo, experiencia previa de los participantes.
\end{itemize}

\section{Diseño del experimento}
El experimento seguirá un diseño \textbf{intra-sujetos contrabalanceado}. Cada participante aplicará ambos métodos (A/B Testing y Recorrido Pluralista) sobre dos conjuntos de tareas diferentes, en sesiones separadas por 24 horas para mitigar los efectos de aprendizaje y fatiga.  
El orden de aplicación de los métodos será aleatorizado para contrarrestar sesgos de orden.


\subsection{Chatty}

El presente experimento tiene como objetivo comparar la aplicación de dos métodos de evaluación de usabilidad —A/B Testing y Recorrido Pluralista— cuando son utilizados por desarrolladores de software en el contexto de la evaluación de una aplicación web. A través de este diseño se pretende obtener evidencia empírica sobre cuál de los dos métodos resulta más adecuado y eficiente desde la perspectiva de los propios evaluadores, considerando tres variables principales: satisfacción, usabilidad percibida y eficiencia, esta última medida tanto en tiempo invertido como en esfuerzo percibido.

De acuerdo con el marco GQM (Goal-Question-Metric), el propósito del experimento es analizar el comportamiento y las percepciones de los desarrolladores al aplicar ambos métodos de evaluación. La pregunta que guía el estudio es: ¿qué método proporciona una mejor experiencia de uso y resultados más satisfactorios a los evaluadores de usabilidad? Para responderla, se utilizarán métricas tanto objetivas (tiempos de ejecución, número y severidad de los problemas detectados) como subjetivas (puntuaciones de satisfacción y usabilidad percibida obtenidas mediante el cuestionario USE adaptado).

El diseño experimental se estructura en torno a tres hipótesis principales. En primer lugar, se plantea que no existen diferencias significativas en la satisfacción de los desarrolladores al aplicar A/B Testing o Recorrido Pluralista, aunque se espera observar una mayor satisfacción en el método más intuitivo o colaborativo. En segundo lugar, se plantea que no existen diferencias en la usabilidad percibida de los métodos, pero se anticipa que uno de ellos podría ser percibido como más fácil de aplicar. Finalmente, se formula la hipótesis de que no existen diferencias en la eficiencia entre ambos métodos, medida como el tiempo total necesario para realizar las tareas y el esfuerzo subjetivo requerido, aunque se espera que A/B Testing, al ser más automatizado, requiera menos tiempo que el Recorrido Pluralista.

En este experimento, la variable independiente es el método de evaluación de usabilidad empleado, que puede ser A/B Testing o Recorrido Pluralista. Las variables dependientes son la satisfacción del desarrollador, la usabilidad percibida del método, la eficiencia (medida en tiempo y esfuerzo) y la efectividad, entendida como la cantidad y severidad de los problemas de usabilidad detectados. Como variables de control se consideran el nivel de experiencia del participante, la complejidad de las tareas asignadas y el orden en que se aplican los métodos.

El diseño elegido es de tipo intra-sujetos contrabalanceado. Cada participante aplicará ambos métodos de evaluación sobre distintos prototipos de una misma aplicación web, de modo que se puedan comparar directamente las percepciones individuales sin la influencia de diferencias entre sujetos. Para evitar el efecto de aprendizaje, los participantes se dividirán en dos grupos. El primer grupo aplicará primero el método A/B Testing y posteriormente el Recorrido Pluralista, mientras que el segundo grupo seguirá el orden inverso. Las sesiones estarán separadas por al menos veinticuatro horas, con el fin de mitigar posibles sesgos derivados de la familiaridad con las tareas o el sistema. Además, los prototipos serán contrabalanceados entre los grupos para garantizar que ambos métodos se apliquen sobre versiones equivalentes de la aplicación.

La muestra estará compuesta por entre dieciséis y veinte desarrolladores de software, incluyendo tanto estudiantes de posgrado como profesionales con experiencia en desarrollo web o en diseño de interfaces. Los participantes deberán contar con conocimientos básicos sobre usabilidad o experiencia de usuario y disponibilidad para asistir a dos sesiones experimentales. Se excluirán aquellos que hayan participado en el piloto del experimento o que conozcan previamente los prototipos utilizados. Este tamaño muestral se considera adecuado para un diseño intra-sujetos con un efecto moderado y una potencia estadística aceptable.

Los objetos experimentales serán dos prototipos web interactivos que representan versiones diferentes de la misma aplicación, con funcionalidades equivalentes y una complejidad moderada. Las tareas que los desarrolladores deberán realizar serán realistas y de corta duración, por ejemplo, localizar un producto y simular una compra, modificar una configuración en el perfil de usuario o buscar información específica dentro del sistema. En el método A/B Testing, se evaluarán las diferencias entre las dos versiones de la interfaz, registrando el rendimiento y los tiempos de interacción. En el caso del Recorrido Pluralista, los desarrolladores participarán en una sesión grupal junto a un diseñador y un experto en usabilidad, discutiendo colectivamente la ejecución de las tareas y los problemas detectados.

El procedimiento experimental constará de dos sesiones por participante. En la primera, se explicará brevemente el método a utilizar y las tareas que deberán completarse. A continuación, el participante aplicará el método correspondiente sobre uno de los prototipos, registrándose los tiempos, observaciones y hallazgos detectados. Una vez finalizada la sesión, se completará el cuestionario USE adaptado, que mide la percepción de utilidad, facilidad de uso, facilidad de aprendizaje y satisfacción general con el método aplicado. En la segunda sesión, que se llevará a cabo al menos un día después, el participante repetirá el procedimiento aplicando el segundo método sobre el segundo prototipo. Al finalizar, se recogerán de nuevo las métricas objetivas y las percepciones subjetivas. En el caso del Recorrido Pluralista, se registrará tanto el tiempo total de la sesión grupal como la participación individual de cada desarrollador, con el fin de normalizar los datos y poder compararlos con el A/B Testing.

Para la recopilación de datos se utilizarán diversas herramientas. El tiempo por tarea se medirá mediante un software de registro automático; los hallazgos de usabilidad se documentarán en una plantilla estandarizada donde se indique la descripción del problema, su severidad y frecuencia. Los cuestionarios USE y SUS permitirán cuantificar la percepción de usabilidad y satisfacción de los participantes, mientras que un breve formulario demográfico recogerá información sobre la experiencia y el rol de cada desarrollador. Además, se almacenarán observaciones cualitativas y comentarios de los participantes sobre las ventajas y limitaciones percibidas en cada método.

El análisis de los resultados combinará técnicas cuantitativas y cualitativas. Se realizará un análisis descriptivo de las puntuaciones obtenidas en los cuestionarios y de los tiempos registrados, calculando medias, medianas y desviaciones estándar. Posteriormente, se aplicarán pruebas estadísticas inferenciales, como la prueba t para muestras relacionadas o el test de Wilcoxon cuando los datos no sigan una distribución normal, con un nivel de significación de $\alpha = 0.05$. También se calcularán los tamaños del efecto (Cohen’s d) para estimar la magnitud de las diferencias observadas. Los comentarios abiertos se analizarán mediante codificación temática, identificando patrones recurrentes en las opiniones de los desarrolladores sobre los métodos comparados.

Con el fin de garantizar la validez interna, el orden de aplicación de los métodos se contrabalanceará y las sesiones se espaciarán en el tiempo para reducir efectos de aprendizaje. La validez externa se abordará seleccionando participantes con distintos niveles de experiencia, lo que permitirá una mejor generalización de los resultados. La validez de constructo se refuerza mediante el uso de instrumentos validados, como las escalas USE y SUS, mientras que la validez de conclusión se preservará mediante un análisis estadístico apropiado y el control de la potencia del estudio. 

Antes de la ejecución definitiva se realizará un piloto con tres a cinco desarrolladores, con el objetivo de validar la claridad de las instrucciones, la duración de las sesiones y la adecuación de las tareas. Los resultados del piloto servirán para ajustar los materiales y tiempos, y detectar posibles problemas en la instrumentación o el análisis. Tras el piloto, se planifica un cronograma de cinco semanas: la primera dedicada al diseño y revisión del protocolo, la segunda al piloto y ajustes, las semanas tres y cuatro a la ejecución de las sesiones experimentales y la quinta al análisis de resultados y redacción del informe final.

En conjunto, este diseño experimental permitirá comparar de forma rigurosa y controlada la experiencia de los desarrolladores al aplicar los métodos A/B Testing y Recorrido Pluralista, evaluando sus ventajas, limitaciones y adecuación para ser empleados en contextos de desarrollo de software orientado a la usabilidad.


\section{Selección de sujetos}

La selección de los participantes se realizará de manera intencionada, buscando garantizar la representatividad del perfil de usuario objetivo del estudio: desarrolladores de software con conocimientos básicos en usabilidad o experiencia de usuario (UX). Dado que el propósito del experimento es comparar la aplicación de los métodos A/B Testing y Recorrido Pluralista desde la perspectiva de evaluadores técnicos, resulta fundamental que los sujetos cuenten con una comprensión general de los principios de diseño de interfaces y evaluación de sistemas interactivos.

El estudio se dirigirá a un grupo de entre 16 y 20 participantes, un tamaño muestral adecuado para un diseño intra-sujetos contrabalanceado, donde cada participante aplica ambos métodos. Este rango permite obtener una potencia estadística suficiente para detectar diferencias de tamaño medio (Cohen's $d \approx 0.5$) con un nivel de significación de 0.05, reduciendo a la vez la variabilidad interindividual.

\subsection*{Criterios de inclusión}
\begin{itemize}
    \item Ser desarrollador o estudiante avanzado de ingeniería de software, diseño de interacción o disciplinas afines.
    \item Poseer conocimientos básicos sobre usabilidad o experiencia de usuario, acreditados mediante formación previa o experiencia práctica.
    \item Tener familiaridad con interfaces web interactivas.
    \item Contar con disponibilidad para asistir a dos sesiones experimentales, separadas por al menos 24 horas.
    \item Aceptar voluntariamente participar en el estudio, firmando el consentimiento informado.
\end{itemize}

\subsection*{Criterios de exclusión}
\begin{itemize}
    \item Haber participado previamente en el piloto del experimento o en estudios similares que involucren los mismos métodos.
    \item Poseer un conocimiento profundo o especializado sobre los prototipos empleados, lo que podría sesgar la evaluación.
    \item Presentar dificultades técnicas o de comunicación que impidan el correcto desarrollo de las tareas experimentales.
\end{itemize}

\subsection*{Procedimiento de reclutamiento}
Los participantes serán reclutados a través de convocatorias internas en facultades de ingeniería y diseño, y mediante invitaciones personales a profesionales en activo del ámbito del desarrollo web. Se ofrecerá información detallada sobre los objetivos del estudio, la naturaleza de las tareas a realizar y la duración estimada de cada sesión (aproximadamente 60 minutos). La participación será voluntaria y no remunerada, aunque se podrá ofrecer una constancia de participación académica.

Antes de iniciar el experimento, cada participante completará un cuestionario demográfico donde se recogerán datos como edad, nivel educativo, años de experiencia en desarrollo, conocimiento previo de técnicas de evaluación de usabilidad y frecuencia de participación en proyectos web. Esta información servirá para describir la muestra y analizar posibles correlaciones entre la experiencia previa y las percepciones de los métodos evaluados.

\subsection*{Consideraciones éticas}
El estudio cumplirá con los principios éticos establecidos por la Declaración de Helsinki y las normas institucionales sobre investigación con participantes humanos. Todos los sujetos firmarán un consentimiento informado en el que se garantice:
\begin{itemize}
    \item La confidencialidad de los datos recogidos.
    \item El uso exclusivo de la información con fines académicos y de investigación.
    \item La posibilidad de abandonar el estudio en cualquier momento, sin consecuencias.
\end{itemize}
Asimismo, los datos personales serán anonimizados y almacenados de forma segura, cumpliendo con la normativa de protección de datos vigente.

\section{Objetos e instrumentación}

Los objetos experimentales serán dos versiones interactivas de una misma aplicación web, denominadas versión A y versión B, que presentan diferencias en su diseño visual y 
disposición de los elementos de la interfaz. Ambas versiones mantienen la misma complejidad funcional, permitiendo que las diferencias observadas en los resultados se deban exclusivamente al método 
de evaluación empleado y no a variaciones en la dificultad de las tareas. Estas versiones servirán como base para la comparación de los dos métodos de evaluación de usabilidad propuestos en este experimento.

Durante la aplicación del método A/B Testing, los participantes interactuarán individualmente con ambas versiones del prototipo, 
realizando un conjunto de tareas representativas de uso cotidiano, como localizar un producto, completar una compra simulada o modificar una 
configuración en el perfil de usuario y buscar información específica dentro del sistema. En el caso del Recorrido Pluralista, los 
participantes se organizarán en pequeños grupos junto con un diseñador gráfico y un experto en usabilidad, aplicando el método 
sobre el mismo conjunto de tareas de forma colaborativa sobre el mismo conjunto de tareas. A lo largo de estas sesiones, se analizarán colectivamente 
los pasos de interacción, se discutirán los problemas detectados y se propondrán posibles mejoras en el diseño. Las tareas han sido seleccionadas por su 
relevancia y que sean comparables entre ambos métodos sin generar efectos de fatiga o aprendizaje. 


Para la recogida de datos se emplearán distintos instrumentos de medición que permitirán obtener información tanto cuantitativa como cualitativa: 

\begin{itemize}
    \item \textbf{Registro del tiempo empleado.} El tiempo empleado en la ejecución de las tareas se registrará mediante un cronómetro o software de registro automático, lo que permitirá calcular la eficiencia de cada participante en ambos métodos. 
    \item \textbf{Documentación de problemas de usabilidad.} Los problemas de usabilidad detectados se documentarán en una plantilla estructurada en la que constará su descripción, severidad y frecuencia de aparición.
    \item \textbf{Cuestionario SUS.} Una vez finalizada cada sesión experimental, los participantes completarán el cuestionario, compuesto de diez preguntas con una escala de respuesta de 1 a 5, que permitirá evaluar de manera estandarizada la percepción de usabilidad del sistema.
    \item \textbf{Escala de satisfacción.} Además, se incluirá una escala de satisfacción general de tipo Likert(1--7) que permitirá valorar el grado de satisfacción del participante con el método aplicado.
    \item \textbf{Preguntas abiertas.} Finalmente, se plantearán preguntas abiertas orientadas a recoger impresiones cualitativas sobre la experiencia, tales como la percepción de facilidad de uso, las ventajas y limitaciones de cada método o las dificultades encontradas durante la evaluación.  
\end{itemize}

Antes de comenzar con las sesiones experimentales, se administrará un breve cuestionario demográfico con el fin de recoger información sobre el perfil de los participantes, incluyendo 
edad, formación, experiencia previa en desarrollo de software y familiaridad con técnicas de evaluación de usabilidad. Durante las 
sesiones del Recorrido Pluralista, se realizarán además observaciones directas y se registrarán comentarios verbales de los participantes, con el objetivo 
de complementar los datos cuantitativos con información cualitativa sobre las percepciones, actitudes y dinámicas de grupo. Todos los datos recopilados 
serán tratados de forma confidencial y anonimizados, garantizando la protección de la información personal y el cumplimiento de los principios éticos establecidos
para investigaciones con participantes humanos.





\section{Evaluación de la validez}

\textbf{Validez interna:} se controlará el efecto orden mediante contrabalanceo. Se mantendrá la misma complejidad de tareas y condiciones experimentales.  

\textbf{Validez externa:} los resultados serán aplicables a contextos similares (evaluaciones de usabilidad de aplicaciones web con participantes semiexpertos).  

\textbf{Validez de constructo:} las métricas SUS y Likert se seleccionan por su fiabilidad y validez en estudios de usabilidad.  

\textbf{Validez de conclusión:} se emplearán pruebas t pareadas (o Wilcoxon si no hay normalidad) con $\alpha=0.05$, y tamaños del efecto (Cohen’s d) para cuantificar diferencias.

% -------------------------------------------------------------------
\chapter*{Referencias}
\addcontentsline{toc}{chapter}{Referencias}
\begin{itemize}
	\item Esto es referncia buscada sobre qué es el pluralistic walk...\cite{PluralisticWalkthrough}
\end{itemize}


Lo de abajo es puro ChatGPT(no me escondo)
\begin{itemize}
    \item Bias, R. (1994). \textit{The Pluralistic Usability Walkthrough: Coordinated Empathies}. In Nielsen \& Mack (Eds.), Usability Inspection Methods.
    \item Brooke, J. (1996). \textit{SUS: A Quick and Dirty Usability Scale}. Usability Evaluation in Industry.
    \item Kohavi, R., Longbotham, R., Sommerfield, D., \& Henne, R. (2009). \textit{Controlled experiments on the web: Survey and practical guide}. Data Mining and Knowledge Discovery, 18(1).
    \item Nielsen, J. (1994). \textit{Usability Engineering}. Morgan Kaufmann.
    \item Rubin, J., \& Chisnell, D. (2008). \textit{Handbook of Usability Testing: How to Plan, Design, and Conduct Effective Tests}. Wiley.
    \item Wohlin, C., et al. (2012). \textit{Experimentation in Software Engineering}. Springer.
\end{itemize}

% BIBLIOGRAFIA %
\cleardoublepage

\printbibliography[heading=bibintoc,title={Bibliografía}]
% -------------------------------------------------------------------
\appendix

\chapter{Anexo I: Tareas de evaluación}
Cada participante completará un conjunto de tareas representativas en la aplicación web.  
\begin{itemize}
    \item \textbf{Tarea 1:} Localizar un producto y completar una compra simulada.  
    \item \textbf{Tarea 2:} Cambiar una configuración de usuario en el perfil.  
\end{itemize}
En A/B Testing, se compararán tiempos y errores entre versiones A y B.  
En el Recorrido Pluralista, se discutirán los pasos de interacción con un grupo de tres evaluadores (usuario, diseñador y experto).

\chapter{Anexo II: Cuestionario de satisfacción y usabilidad}
\begin{itemize}
    \item Escala SUS (10 ítems, 1--5).  
    \item Escala de satisfacción general (Likert 1--7).  
    \item Preguntas abiertas sobre percepción del método aplicado.  
\end{itemize}

\end{document}